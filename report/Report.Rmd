---
title: "tidyMC"
subtitle: "An easy-to-use package for Monte-Carlo Simulations"
type: "Report"
author: "Ignacio Moreira Lara, Stefan Linner, Konstantin Lehmann"
discipline: "M.Sc. Econometrics"
date: "`r Sys.Date()`"
supervisor: "Jens Klenke"
secondsupervisor: "Martin C. Arnold"
studid: 230658, 233565, 229994
cols_authors: 4
estdegree_emester: "Summer Term 2022"
deadline: "06.09.2022"
output:
  pdf_document:
    extra_dependencies: ["lmodern", "mathtools", "amsmath", "amsfonts", "soul"]
    keep_tex: yes
    template: template.tex
    fig_caption: yes
    citation_package: biblatex
    number_sections: false
toc: false
lot: false
lof: false
graphics: true
biblio-title: References
fontsize: 10pt
geometry: lmargin=2.5cm,rmargin=2.5cm,tmargin=2.5cm,bmargin=2.5cm
biblio-files: references_tidy.bib
classoption: a4paper
language: english
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# library(profvis)
# library(purrr)
# library(dplyr)
# library(tibble)
# library(rlang)
# library(ggplot2)
library(tidyMC)
library(magrittr)
# devtools::load_all()
```

# Introduction
Monte Carlo Simulations (henceforth MCS) are used to study the properties of econometrics inference techniques by simulation. 
They are almost always part of theoretical econometric research to study the performance of some inference technique. They supplement theoretical research most often in one of four ways. Firstly, they are used to assess the performance of asymptotically valid techniques in smaller samples. Secondly, they are  used to assess how robust a technique is to violations of its theoretical assumptions. Thirdly, they allow to compare the performance of different techniques for a given data generating process (DGP). Fourthly, MCS allows to investigate the properties of inference techniques for which no analytic solution exists.  Moreover, MCS itself can be used as a statistical inference technique. For example, Bootstrap Inference can be conceptualized as a special case of MCS. Beyond these examples, there are many more areas where MCS is used. However, independent of its use-case, easy and efficient implementation of MCS is currently only sparsely available.

<!-- Na: Monte Carlo Simulations (henceforth MCS) are used to study the properties statistical techniques and theories by simulation.
They are almost always part of theoretical statistical research to research the empirical behavior of some theory. MCS have been proven to be usefull in almost all fields of statistics, among some examples we have: the assessment of the performance of asymptotically valid techniques in smaller samples,the analysis of the robustness of statistical techniques to violations of theoretical assumptions, or to compare the performance of different methodologies when applied to a given data generating process (DGP). Moreover, MCS are also regarded as a technique of statistical inference by themselves. For example, Bootstrap Inference can be conceptualized as a special case of using MCS. Independent of its use-case, easy and streamed-lined implementations of MCS are currently sparsely available.-->

<!-- Na: With our \texttt{tidyMC} package, we want to offer academic and private users an easy and efficient manner to include MCS in their application through the use of the programming language R. For one, using \texttt{`tidyMC`} we enable the user a way to easily speed up MCS by providing efficient parallelization options over a pre-specified parameter grid. Because MCS involves repeated computation, using parallel workers allows for significant computation time reductions. For another, \texttt{`tidyMC`} returns an easy-to-work-with output, which allows the user to access the result of all simulations for every combination of the parameter grid. Moreover, \texttt{`tidyMC`} provides functions to effectively communicate the results of the MCS in a highly customizable setting.  Using the output, the simulation results can then be easily visualized using the package's plot function. Since the function returns a ggplot object, users can customize the object to their liking. Additionally, the package provides a function that converts the results into print-ready LaTeX tables, which are heavily customizable and thereby allow the users to effectively present their results. -->


<!-- Na: This report is structured as follows. Section \@ref(monte-carlo-simulation) gives an introduction as to why and how MCS work, and an example of the properties of OLS is presented. Section \@ref(package-principles) explains the coding practices followed during the development and gives a conceptual overview of how MCS are implemented in R. Section \@ref(vignette) presents tidyMC's vignette and gives a detailed description on the functionalities of the package, while providing an an easy-to-follow guide on how to implement MCS. Section \@ref(comparison-to-other-monte-carlo-approaches-in-r) benchmarks the performance of tidyMC in comparison to the MonteCarlo package and other potential MCS implementations.  Section \@ref(conclusion) concludes.-->

With our \texttt{tidyMC} package, we want to enable researchers to easily and efficiently include MCS in their research using the programming language R. For one, \texttt{`tidyMC`} allows to easily speed up MCS by providing efficient parallelization options over a pre-specified parameter grid. Because MCS involves repeated computation, using parallel workers allows for significant computation time reductions. For another, \texttt{`tidyMC`} returns an easy to work with output. The output allows to access the result of all simulations for every parameter combination in the parameter grid. Moreover, \texttt{`tidyMC`} provides functions to effectively communicate the results of the MCS.  Using the output, the simulation results can then be easily visualized using the package's plot function. Because the function returns a ggplot object, researchers can customize the object to their liking. Additionally, the package provides a function that converts the results into publication-ready LaTex tables. The table is heavily customizable and thereby allows researchers to effectively communicate their results. 

This report is structured as follows. Section \@ref(monte-carlo-simulation) gives an introduction to why and how Monte Carlo 
simulations work and provides a simple OLS example. Section \@ref(package-principles) explains the coding practices we followed and gives a conceptual overview of how we implemented MCS in R. Section \@ref(vignette) presents tidyMC's vignette. The vignette gives an easy-to-follow guide on how to implement MCS using the tidyMC package. Section \@ref(comparison-to-other-monte-carlo-approaches-in-r) compares the performance of tidyMC to the performance of the MonteCarlo package and other potential MCS implementations.  Section \@ref(conclusion) concludes. 

With our \texttt{tidyMC} package, we want to enable researchers to easily and efficiently include MCS in their research using the programming language R. For one, \texttt{`tidyMC`} allows to easily speed up MCS by providing efficient parallelization options over a pre-specified parameter grid. Because MCS involves repeated computation, using parallel workers allows for significant computation time reductions. For another, \texttt{`tidyMC`} returns an easy to work with output. The output allows to access the result of all simulations for every parameter combination in the parameter grid. Moreover, \texttt{`tidyMC`} provides functions to effectively communicate the results of the MCS.  Using the output, the simulation results can then be easily visualized using the package's plot function. Because the function returns a ggplot object, researchers can customize the object to their liking. Additionally, the package provides a function that converts the results into publication-ready LaTex tables. The table is heavily customizable and thereby allows researchers to effectively communicate their results. 

This report is structured as follows. Section \@ref(monte-carlo-simulation) gives an introduction to why and how Monte Carlo 
simulations work and provides a simple OLS example. Section \@ref(package-principles) explains the coding practices we followed and gives a conceptual overview of how we implemented MCS in R. Section \@ref(vignette) presents tidyMC's vignette. The vignette gives an easy-to-follow guide on how to implement MCS using the tidyMC package. Section \@ref(comparison-to-other-monte-carlo-approaches-in-r) compares the performance of tidyMC to the performance of the MonteCarlo package and other potential MCS implementations.  Section \@ref(conclusion) concludes. 

# Monte Carlo Simulation {MCS}
MCS allows analyzing the properties of classic econometric inference techniques. As a simulation-based technique, MCS applies a statistical procedure to many synthetically created samples. The repeated application of the procedure to a fully known DGP helps to investigate the properties of statistical techniques in a wide set of settings. It is possible to use MCS as a simulation-based inference technique itself. In this section, we want to give a brief overview of how and in which circumstances MCS work , mainly following <!-- \citep{kiviet_monte_2011}. -->



## Pseudo Random Number Generation and the Data Generating Process
Using MCS on computers has the great advantage that, with the necessary information, the simulation results can be replicated on most machines. This is possible because, given seed and algorithm, the numbers created by a random number generator are completely reproducible. 
MCS generally start with a synthetically created i.i.d. sample. Computers are, however, not able to generate truly random draws from different distributions. Instead, the computer draws from different distributions that are generated through pseudo-random draws from a uniform distribution.  Draws from a uniform distribution are created by using so-called random number generators (RNG). These algorithms are applied to a natural number, called the seed. The resulting values are pseudo-random because they are indistinguishable from truly random numbers but are fully determined by the combination of the algorithm and the seed. The combined knowledge of the algorithm and the seed allows exact replication of a series of pseudo-random numbers generated. The purpose of the \texttt{`tidyMC`} -package is to additionally allow easy parallelization of the MCS. With parallel computing, special attention has to be paid to creating disjoint and sufficiently long sets of draws from a uniform distribution. Our package builds on the Lâ€™Ecuyer-CMRG RNG streams implemented in \texttt{`furrr::furrr_options`}. The algorithm creates reproducible sets of numbers for each parallel worker, using an integer seed of at most length 7. \hl{Alternatively, a seed of length 1 is accepted, which corresponds to a valid seed of length 7}. Because the algorithm creates a subset of random numbers for each worker, the stream and hence the MCS results are only reproducible if the same number of parallel workers is used. \hl{Moreover, our function allows supplying user-generated lists of random variables.} 
\hl{Complex multivariate distributions can then be simulated as functions of different standard distributions. This allows us to generate and work with distributions that are analytically not manageable.}

<!--The possibility to replicate the draws allows for exactly reproducing results that build on the pseudo-randomly generated number on different computers.   The most common algorithm, as well as R's standard algorithm, used for the generation of pseudo-random draws from a standard uniform distribution, is the Mersenne-Twister algorithm. There are however more algorithms available. In R it is also possible to specify your own algorithm to create pseudo-random numbers.

Generating pseudo-random numbers from more complex distributions uses the distribution's cumulative distribution function (CDF). It can be shown that every random variable $X$ has a CDF $F$ if $X = F^{-1}(U)$, where U is a random variable uniformly distributed on $(0,1)$. Pseudo-random draws from different probability distributions are conceptually implemented by applying the inverse of CDF to pseudo-random numbers from the uniform distribution. Direct application of the inverse CDF is however often computationally time-consuming and requires that the inverse CDF is analytically available. To account for the two shortcomings different approaches have been developed for specific distributions, that also easily extend to random vectors. While they build on the idea to use the inverse of the CDF, their concrete design is out of the scope of this paper. A general overview can be found in the documentation of the respective R-functions. --> 



## Monte Carlo Distribution Approximation
MCS is most commonly used to infer properties of the distribution of statistics in a fixed setting, i.e. for a prespecified DGP, hence the simulation results hold only for this. Since it additionally only approximates the distribution numerically, we need to control for the resulting approximation inaccuracies.  In MCS we generally simulate the distribution of a statistic $q_n$. The statistic can often be expressed as a function of a parameter vector $\beta$, some deterministic variables $D$, some random variables $v$, and a given number of observations, s.t. $q_n = q_n(\beta,D,v,n)$. What a Monte Carlos simulation ultimately achieves is a numerical approximation of the true distribution of $q_n$ for the specified DGP. Let $q_n^R$ be the statistic generated by the $R^th$ Monte Carlo Simulation. Then the histogram of all $q_n^R$ is an unbiased and consistent estimator of $q_n$. Thus, the precision of the approximation is controlled by setting the number of Monte Carlo estimates. We can then use different statistics such as mean and variance on $q_n^R$ to summarize the distribution of the statistic for the prespecified DGP. The approach can of course be easily extended to a vector of statistics $q_n$. 


## Monte Carlo Best Practices
@cite{dude} gives a few things that need to be considered when doing and presenting MCS. The results must allow the audience to get a precise picture of the Monte Carlo experiment. MCS generally involves testing the attributes of $q_n$ not only for one DGP but for a wide set of DGPs that may include \hl{nuisance} parameters that may significantly alter the distribution.

We present one example of a MCS. \hl{Instead of going through every use case, we next describe one specific MCS use case. The insights from that use case should however be easily transferable to other MCS applications.} One way to perform MCS is mimic analytic derivations. For example, if properties of an asymptotically consistent technique are studied, the MCS should include different nuisance parameters over increasing sample sizes. The report of the results should then include the technique's key performance indicators, such as bias and efficiency, over different combinations of nuisance parameters and sample sizes. As the parameters are the explanatory variables of the MCS @cite{dude}, their values have to be chosen with care to appropriately represent the results from the experiment.  The reported representative selection of sample size and nuisance parameters should then show the - potentially nonlinear- behavior of the key indicators of the performance of the technique. As the later sections will show, \texttt{`tidyMC`} provides easy options to define an arbitrarily large parameter grid to use for the MCS as well as user-defined performance indicators  The packages summary functions allow the researcher to get a quick overview of the results of the combinations defined in the parameter grid. The plot and table functions allow afterward to easily communicate the desired results. Due to the flexible design of the \texttt{`tidyMC`}, the parameter grid can easily be extended to include different estimators for comparisons. It also allows using the distribution of the data itself to generate a new sample, from which we can then infer the properties of an estimator.



<!-- ### Presenting MCS findngs
p. 122 add maybe here? For example we might be interested in the ability of OLS to estimate the variable parameter $\beta_1$ of a simple linear regression model with deterministic regressor. -->
<!-- In that case specify the model $y_i = \beta_0 + \beta_1 x_i + \epsilon_i$ with corresponding true population paramterers $\theta  = (\beta_0, \beta_1)$, $D = X$ a $n \times 2$ matrix of the deterministic x and the intercept $\beta_0$, and $c = \epsilon$ a $n \times 1$ of $\mathcal{N}(0, \sigma_\epsilon)$ as a normally distributed error term. Using OLS, we estimate $\hat{\beta_1}$ as the second element of $(X^TX)^{-1}X^Ty$. With OLS then $\hat{\beta}_1(\theta, D, v)$. In a MCS we would then generate r $\hat{\beta_1}$ to study how well OLS is able to capture the true $\beta_1$.  -->
<!-- Show distribution of interval  -->

## OLS consistency

To demonstrate how a MCS works, we provide an example using the estimation of a linear model using the ordinary least squares(OLS) estimator. Given a dependent variable $y$ and a set of i.id. regressors $X = \{x_1, x_2\}$ we consider the linear DGP 
\begin{equation}
	\label{eq_DGP}
	y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \varepsilon,
\end{equation}  
where $\beta  = \{\beta_0, \beta_1, \beta_2\}$ are the coefficients and $\varepsilon$ is a normally distributed error term with variance $\sigma^2$, i.e. $\varepsilon \sim \mathcal{N}(0,\sigma^2)$. The corresponding OLS estimators $\hat{\beta}$ and $s^2$ for $\beta$ and $\sigma^2$  are
\begin{align}
	\hat{\beta} = (\boldsymbol{X}'\boldsymbol{X})^{-1} \boldsymbol{X}Y,\\
	s^2 =   \frac{1}{n-k-1} \hat{\varepsilon}' \hat{\varepsilon},
\end{align}
where $k = 3$ is the number of regressors and $\hat{\varepsilon}$ is the vector of residuals. Both estimators are consistent and unbiased. Accordingly OLS should be able to correctly estimate the coefficients for every sample size, while the precision of the estimates should increase in the sample size. 

\noindent Using a MCS we can demonstrate the properties of the OLS estimator. Fixing the coefficients $\beta = \{1, 4, 5\}$ and $\sigma^2 = 3$, we generate different DGPs using different normal distributions to generate the dependent variables  $x_1$ and $x_2$. Additionally, we generate $\varepsilon$ from its respective distribution, and we estimate OLS on this sample. The number of observations we use is set to $n = \{100, 200, 300\}$, which will be used to assess the convergence of the OLS estimators.  We repeat the estimation 10000 times for each $n$.

The results demonstrate the performance of OLS estimation with increasing sample sizes. As expected figures \ref{fig:ols_b1}, \ref{fig:ols_s2} and table \ref{tab:ols_table} confirm that a bigger sample size leads to a more precise estimation of the underlying population values. Comparing both panels, we see that this behavior is just confirmed, as the estimated values do not differ and they become more precise.


```{r, echo = FALSE, eval = TRUE, results = "hide", message=FALSE, fig.show='hide'}

ols_test <- 
  function(b0, b1, b2, n, sigma2, param_x1, param_x2, inc_x2){
    
    # generation of data
    x1 <- rnorm(n = n, mean = param_x1[1], sd = param_x1[2])
    x2 <- rnorm(n = n,  mean = param_x2[1], sd = param_x2[2])
    e <- rnorm(n, sd = sqrt(sigma2))
    y <- b0 + b1*x1 + b2*x2 + e
    
    if (inc_x2 == 0){
      x2 <- x2 * inc_x2
    }
    
    # application of method
    estim <- lm(y ~ x1 + x2)
    
    # evaluation of the result for a single repetition and parameter combination
    out <- list(B0 = estim$coefficients[1],
                B0_se = summary(estim)$coefficients[1,2],
                B1 = estim$coefficients[2],
                B1_se = summary(estim)$coefficients[2,2],
                B2 = estim$coefficients[3],
                sigma2 = var(estim$residuals))
    return(out)
}

param_list_ols <-
  list(n = c(100, 200, 300), inc_x2 = c(0,1), b2 = c(0,4))
ols <- future_mc(fun = ols_test,
                 repetitions = 10000,
                 param_list = param_list_ols,
                 b0 = 1,
                 b1 = 4,
                 param_x1 = c(1,2),
                 param_x2 = c(3,4),
                 sigma2 = 3)
```

```{r ols_table, echo = FALSE}

tidy_mc_latex(summary(ols),
              parameter_comb =  list(b2 = 4),
              repetitions_set = c(10, 10000),
              kable_options = list(
                col.names = c("N. Observations",
                              "$\\beta_2$",
                              "$\\hat{\\beta}_0$",
                              "$\\sigma(\\hat{\\beta}_0)$",
                              "$\\hat{\\beta}_1$",
                              "$\\sigma(\\hat{\\beta}_1)$",
                              "$\\hat{\\beta}_2$",
                              "$\\sigma(\\hat{\\beta}_2)$",
                              "$s^2$"),
                caption = "Ommited variable bias MC results",
                escape = FALSE)) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position")

```


```{r ols_b1, echo = FALSE, fig.cap="MC $\\beta_1$ results"}
(plot(ols, plot = FALSE, parameter_comb = list(inc_x2 = 1, b2 = 4))$B1)

```

```{r ols_s2, echo = FALSE, fig.cap="MC $s^2$ results"}
(plot(ols, plot = FALSE, parameter_comb = list(inc_x2 = 1, b2 = 4))$B1_se)

```



##Ommited variable bias and irrelevant regressor inclusion

Moreover, a common problem for estimation is the inclusion of suitable regressors into the model. Both the inclusion of irrelevant variables and the absence of relevant ones into the regression model cause problems when estimating the true parameters. In this section, we will test the impact both of these problems on the estimated values.

First, we test the consequences of including an irrelevant variable into a model. For the DGPs we follow the same structure as in \ref{eq_DGP}, but we set $\beta_2 = 0$ which means that $x_2$ has no influence on $y$. \textit{A priori} the expected result is that $\hat{\beta}_2$ associated with this new variable will be 0, while the efficiency of the other estimators of the model will decrease. Empirically, we test this using the same parameter values and model of the base case, only for another DGP.

We present our results in table \ref{tab:irr_ols_table}. As expected, for all sample size values, the estimated $\hat{\beta}_2$ is not different from 0, and $\hat{\beta}_1 $ is estimated correctly. Meanwhile, the estimation of $s^2$ becomes more ineficient and inprecise, compared to the results of the base case. These three patterns only becomes more precise the more MC results we use for the calculation.



```{r irr_ols_table, echo = FALSE}

tidy_mc_latex(summary(ols),
              parameter_comb =  list(b2 = 0, inc_x2 = 1),
              repetitions_set = c(10, 10000),
              kable_options = list(
                col.names = c("N. Observations",
                              "$x_2$ included",
                              "$\\beta_2$",
                              "$\\hat{\\beta}_0$",
                              "$\\hat{\\beta}_1$",
                              "$\\hat{\\beta}_2$",
                              "$s^2$"),
                caption = "Ommited variable bias MC results",
                escape = FALSE
              )) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position")


```


Lastly, we test the effects of estimating a model using only $x_1$ when the underlying DGP follows the structure of \eqref{eq_DGP}, this problem is most commonly known as having an omitted variable bias. Since it is necessary that $x_1$ and $x_2$ share a degree of correlation between them, the absence of one of them in the regression model will cause the available variable to be correlated with the error term, thus violating one of the main assumptions OLS. This correlation will lead to $\hat{\beta}_1$ to be estimated less efficiently (depending on the sign of the correlation) in comparison to the true parameter.


We again follow exactly the same structure as for the base case, only that $x_2$ is not included into the estimation model. To show the loss in efficiency we present the density plots for the Monte Carlo results for $\hat{\beta}_1$ in figure \ref{fig:ommit}. There is a clear difference in term of the variance of the estimated coefficients between the cases for when $x_2$ is included into the model and not. This pattern only repeats itself no matter the number of observations used by the model. Nonetheless, we observe that the OLS estimate remains unbiased in any case.

```{r ommit, echo = FALSE}
(plot(ols, parameter_comb = list(b2 = 4), plot = FALSE)$B1)

```
# Package Principles {MCS}


# Vignette{vignette}

# Package overview

Monte Carlo Simulations aim to study the properties of statistical inference techniques. 
At its core, a Monte Carlo Simulations works through the application of the techniques to repeatedly drawn samples from a pre-specified data generating process.  The `tidyMC` package aims to cover and simplify the whole workflow of running a Monte Carlo simulation in either an academic or professional setting. Thus, `tidyMC` aims to provide functions for the following tasks:

* Running a Monte Carlo Simulation for a user defined function over a parameter grid using `future_mc()`
* Summarizing the results by (optionally) user defined summary functions using `summary.mc()`
* Creating plots of the Monte Carlo Simulation results, which can be modified by the user using `plot.mc()` and `plot.summary.mc()`
* Creating a LaTeX table summarizing the results of the Monte Carlo Simulation using `tidy_mc_latex()`

In the following subsections we will show you how you can implement those tasks using the `tidyMC` package.


## Installing tidyMC

Until now, the `tidyMC` package is not on CRAN, thus you need to download the development version from [GitHub](https://github.com/stefanlinner/tidyMC) as follows:

```{r, eval=FALSE}
# install.packages("devtools")
devtools::install_github("stefanlinner/tidyMC")
```

Afterwards you can load the package:

```{r}
library(tidyMC)

```
Moreover, the following packages will be used in this vignette: 

```{r, warning=FALSE}
# install.packages("magrittr")
library(magrittr)
# install.packages("ggplot2")
library(ggplot2)
```


### Run your first Monte Carlo Simulation with `future_mc()`

`future_mc()` allows you to run a Monte Carlo Simulation for a user defined function and given parameters. The first argument of `future_mc()` is `fun` which has to be a function that handles the generation of data, the application of the method of interest and the evaluation of the result for a single repetition and parameter combination. `future_mc()` handles the generation of loops over the desired parameter grids and the repetition of the Monte Carlo experiment for each of the parameter constellations. Consider the following example for `fun` and note that it performs the required tasks of generating data, applying the method and evaluating the results: 

```{r}
# fun
ols_test <- 
  function(b0, b1, b2, n, sigma2, param_x1, param_x2, inc_x2){
    
    # generation of data
    x1 <- rnorm(n = n, mean = param_x1[1], sd = param_x1[2])
    x2 <- rnorm(n = n,  mean = param_x2[1], sd = param_x2[2])
    e <- rnorm(n, sd = sqrt(sigma2))
    y <- b0 + b1*x1 + b2*x2 + e
    
    if (inc_x2 == 0){
      x2 <- x2 * inc_x2
    }
    
    # application of method
    estim <- lm(y ~ x1 + x2)
    
    # evaluation of the result for a single repetition and parameter combination
    out <- list(b0 = estim$coefficients[1],
                b1 = estim$coefficients[2],
                b2 = estim$coefficients[3],
                sigma2 = var(estim$residuals))
    return(out)
  }
```

The second argument of `future_mc()` is `repetitions` which should be an integer specifying the number of Monte Carlo iterations. While the third argument `param_list` should be a list whose components are named after the parameters of `fun` which should vary for the different Monte Carlo Simulation and each component is a vector containing the desired grid values for the parameter. Consider the following example for `param_list` and note that its components are named accordingly to the parameters of `ols_test`: `n` and `inc_x2`, respectively:

```{r}
# param_list
param_list_ols <- 
  list(n = c(100, 200, 300), inc_x2 = c(0,1))
```

`future_mc()` takes care of creating all possible parameter combinations of `param_list` and runs the Monte Carlo Simulation over all of these \hl{for all possible combinations}. If you don't want to run a Monte Carlo Simulation for every possible parameter combination you can alternatively define `param_table` with a `data.frame` or `data.table` containing the parameter combinations you are interested in. The `...` argument can be used to specify further arguments of `fun` which are not contained in `param_list`. Those arguments will be held fixed for all parameter combinations. In our OLS example the arguments are `b0`, `b1`, `b2`, `sigma2`, `param_x1`, and `param_x2`.

Moreover, there are four formal requirements that `fun` and thus `ols_test` have to fulfill:

* The arguments of `fun` which are present in `param_list` have to be scalar values. Note that the arguments of `ols_test` which are contained in `param_list_ols`: `n` and `inc_x2` are scalar values. The remaining arguments of `ols_test` are allowed to take non-scalar values.
* Every variable used inside `fun` has either to be defined inside `fun` or given as an argument through the `...` argument.
* The value returned by `fun` has to be a named list. In our example the names of the returned list are `b0`, `b1`, `b2`, and `sigma2`.
* The names of the returned values and those of the arguments contained in `param_list` need to be different. Moreover, they cannot be `params`, `repetitions` or `setup` as these names are already occupied. Note that `b0`, `b1`, `b2`, and `sigma2` are the names of the returned values as well as names of arguments of `ols_test`. However, none of those arguments is contained in `param_list_ols`. If we would add either of those variables to `param_list_ols` we would need to change the name of the returned value for the respective variable.

We recommend to even further restrict the return value of `fun` to be a named list of scalars. This allows you to use all comfort functions of the `tidyMC` package. As you can see, we did that for `ols_test`.


The argument `parallelisation_plan` allows the user to set a parallelisation plan. While the argument `parallelisation_options` allows the user to fine tune functions, such as `furrr::future_map()` by `furrr::furrr_options()`. The argument `seed` for `furrr::furrr_options()` can be specified in `parallelisation_options` following the formal requirements of its respective documentation. Moreover, the user can also decide not to run the Monte Carlo in parallel by setting `parallel = FALSE`. To construct `parallelisation_plan` the user needs to provide a list named after the arguments of `future::plan`. The main argument `strategy` needs to provide the specific type of parallelisation the user would like to use and the number of cores which are used in the function. Some of the options for strategy are: `multisession`, `multicore` and `cluster`. We strongly recommend the user to read the documentation of the `future` package for a more detailed instruction of how to set up the different strategies.

As a default `future_mc()` runs a quick check by running a single test-iteration for each parameter combination in order to check for possible errors in `fun`. If a error occurs the user not only receives the error message but also the parameter combinations for which the error occurred:

<!-- maybe also say that tests can be skipped? Additionally maybe also give an example of a parralelisation playn, quickly laying out the main options? -->

```{r, error=TRUE}
set.seed(101)
first_mc_ols <- future_mc(
  fun = ols_test, 
  repetitions = 1000, 
  param_list = param_list_ols, 
  b0 = 1, 
  b1 = 4, 
  b2 = 5, 
  sigma2 = -2,
  param_x1 = c(0,5),
  param_x2 = c(0,6),
  check = TRUE
)
```

The attentive reader might already have noticed that we specified `sigma2 = -2` which doesn't make sense, as the variance of the error term cannot be negative. 
<!-- The attentive reader might have already noticed that we misspecifed the variance ?`sigma2 = -2`. By defintion, the variance is non-negtaive and the sepcified function is hence nonsenscial. As expected, the failed check informs about the source of the mistake, which impacts all parameter combinations specified.-->
This results in a failed check for all parameter combinations, as this parameter is held fixed for any combination. Once we correct that mistake, we can run our first Monte Carlo Simulation:

```{r}
set.seed(101)
first_mc_ols <- future_mc(
  fun = ols_test, 
  repetitions = 1000, 
  param_list = param_list_ols, 
  b0 = 1, 
  b1 = 4, 
  b2 = 5, 
  sigma2 = 2, # correctly specify sigma2
  param_x1 = c(0,5),
  param_x2 = c(0,6),
  check = TRUE
)
```

`future_mc` returns a list of type `mc` and length `r length(first_mc_ols)` consisting of a tibble (`first_mc_ols$output`) containing the return value of `fun` for each iteration and parameter combination. In our case `first_mc_ols$output` contains a column for each output `b0`, `b1`, `b2`, and `sigma2`, as well as a column for each parameter in `param_list_ols` and a column containing the `nice_names` of the parameter combinations. Overall the `first_mc_ols$output` consists of `r nrow(first_mc_ols$output)` rows, i.e., for each parameter combination 1.000 rows: 

```{r}
first_mc_ols$output
```

If `ols_test` would not return a named list of scalars, but a named list of non-scalars, then `first_mc_ols$output` would not contain a column for each output, but a single column containing the named list of non-scalars for each iteration and parameter combination.

Moreover, `first_mc_ols` returns much other information about the Monte Carlo Simulation that can be printed in a dense representation:

```{r}
first_mc_ols
```


### Summarize your results with `summary.mc()`

If `fun` returns a named list of scalars the user can use `summary.mc()` to summarize all Monte Carlo results. The first argument of the function is an object of class `mc` returned by `future_mc()`. The next argument `sum_funs` determines which summarizing functions will be used on the simulation results. The functions can be provided for any combination of: parameter combinations resulting from `param_list`, and the outputs of `fun`. Every specified function can only take one argument, which is the vector (with length `repetitions`) for every output. We will present all customization options of `sum_funs` in a stepwise manner. 

The first option of summarizing the results is given by just providing the `mc` object to `summary.mc`. In this case, `mean()` will be applied to all numeric values and `summary()` to all non-numeric data types. When the summarizing functions return one numeric value (like `mean()`) the results are twofold:

* First, a single scalar result of the function evaluated using the complete output vector is returned in the first element.

* Second, a vector with length `repetitions` of numeric results from the step wise calculation of the function's result across the output's vector. We call this resulting vector as the "path" of the summarizing function. 

Additionally, to save computation time the parameter `which_path` is available to the user who wants to specify for which ouputs the "path" should be calculated. The user needs to provide a character vector with the output names'. Moreover, the options `"all"` (the default) and "none" are also available. 

For the OLS example since all outputs of `ols_test` are numeric, the returned object will be a named nested list composed of four elements named after the `nice_names` returned by `future_mc()`. Each of this elements are itself lists containing the summarized outputs, i.e. `b0`, `b1`, `b2`, and `sigma2`. Lastly each of these are composed by the "path" and scalar result of `mean()`. 


```{r}
# Default
summary_default <- summary(first_mc_ols)
summary_default
str(summary_default[[1]])
```


This nested list structure should give an idea of the reach and flexibility the `sum_funs` argument is allowed to have, since the user can specify a function for each element in this list.

For an intermediate level of customization, the user can provide a combination of summarizing functions for every output, which will be used for all parameter combination. In the case of the OLS example, if we want to apply `mean()` on all estimated coefficients, but we want to use `var()` on the MC results of `sigma2`, the `sum_funs` should have the following structure:

```{r, eval = FALSE}
# summarizing output the same way for each parameter combination with one function combination
sum_funs_ols <- list(b0 = mean, b1 = mean , b2 = mean, sigma2 = var)
```

Moreover, the user can specify any function provided it takes the output vector as only available argument.

Lastly for the last level of customization, a nested list named after the `nice_names` where every element follows the structure of the last example (components named after the outputs and each component is a function) can be specified. We present an example for this:

```{r}
quantile_sum <- function(x) quantile(x, probs = 0.75)

# summarizing output differently for different parameter combinations
sum_funs2 <-
  list(
    list(b0 = quantile_sum, b1 = min, b2 = min, sigma2 = mean),
    list(b0 = mean, b1 = quantile_sum, b2 = mean, sigma2 = mean),
    list(b0 = median, b1 = median, b2 = median, sigma2 = mean),
    list(b0 = max, b1 = max, b2 = max, sigma2 = mean),
    list(b0 = min, b1 = min, b2 = min, sigma2 = quantile_sum),
    list(b0 = mean, b1 = mean, b2 = quantile_sum, sigma2 = quantile_sum)
  )
names(sum_funs2) <- first_mc_ols$nice_names
summary_out_param_spec <- summary(first_mc_ols, sum_funs = sum_funs2)
```

We would like to reiterate that the provided summary functions are not restricted regarding the complexity of their return value. However, the path of the summarized output over all simulation repetitions is only returned if the provided summary functions return a single numeric value. Thus, the following comfort functions `plot.summary.mc()` and `tidy_mc_latex()` will only work in this specific case.


### Plot your Monte Carlo Simulation with `plot.mc()` and `plot.summary.mc()`

If `fun` returns a named list of scalars the user can use `plot.mc()` to generate a list of objects of class `gg` and `ggplot2` for all Monte Carlo results. The first argument of the function is an object of class `mc` returned by `future_mc()`. Using the argument `plot` the user can indicate whether the generated plots should be printed immediately or only returned in a list. The list will contain one plot for each output of `fun` comparing the results of the different simulation setups. In general, `plot.mc()` generates density plots for numeric outputs and bar plots for non-numeric outputs. In our example a plot for `b0`, `b1`, `b2`, and `sigma2` will be returned in a list of length four and as `b0`, `b1`, `b2`, and `sigma2` are all numeric outputs `plot.mc()` will return density plots for each of those:

```{r}
mc_ols_plot <- plot(first_mc_ols, plot = FALSE)
names(mc_ols_plot)
```

As the single list elements are of class `gg` and `ggplot2`, we can easily customize and extend the single plots using familiar `ggplot2` commands: 

```{r}
mc_ols_plot$b1 + 
  ggplot2::geom_vline(xintercept = 4, col = "red") + 
  ggplot2::theme_dark()
```

When creating the plots the user can also subset the setups which he/she would like to see in the plots using the `first_mc_ols$nice_names` in the function argument `which_setup`, or a named list in `parameter_comb`. The single components of the list have to be named after the parameters specified in `param_list` and contain vectors specifying the values of the parameters to filter by. In the ols example we can filter by the parameters `n` and `inc_x2`:

```{r}
# subsetting by nice_names
mc_ols_plot_subset1 <- 
  plot(first_mc_ols, plot = FALSE, which_setup = first_mc_ols$nice_names[4:6])
#subsetting by parameter values
mc_ols_plot_subset2 <- 
  plot(first_mc_ols, plot = FALSE, parameter_comb = list(inc_x2 = 1))

mc_ols_plot_subset1$sigma2
```

Thus, if the user wants distinct plots for every parameter combination, one needs to subset for the plot for any single setup in `first_mc_ols$nice_names`. 

Finally, you can also plot the simulation results for several parameter combination in one single plot by specifying the argument `join` with the respective `first_mc_ols$nice_names`: 

```{r}
mc_ols_plot_joint <- plot(first_mc_ols, plot = FALSE, join = first_mc_ols$nice_names)
mc_ols_plot_joint$b2
```

Please be aware that the only one of the three arguments `which_setup`, `parameter_comb`, and `join` can be specified at the same time.


If the provided summary functions in `summary.mc()` return a single numeric value and thus a path of the summarized output over all simulation repetitions is returned, the user can use `plot.summary.mc()` to plot those paths. The first argument of the function is an object of class `summary.mc` returned by `summary.mc()`. Just as `plot.mc()`, `plot.summary.mc()` returns a list of objects of class `gg` and `ggplot2`. The list will contain one line plot for each output of `fun` displaying the paths of the results of the different simulation setups. The arguments `plot`, `which_setup`, `parameter_comb`, and `join` can be specified the same way as for `plot.mc`: 

```{r}
sum_mc_plot <- plot(summary_default, plot = FALSE)
sum_mc_plot$b1 + 
  ggplot2::geom_vline(xintercept = 100, col = "red") +
  ggplot2::theme(axis.text.x = element_text(angle = 45, hjust = 0.1, vjust = 0.2))

sum_mc_plot_subset1 <- 
  plot(summary_default, plot = FALSE, which_setup = first_mc_ols$nice_names[4:6])

sum_mc_plot_subset2 <- 
  plot(summary_default, plot = FALSE, parameter_comb = list(inc_x2 = 1))

sum_mc_plot_subset2$b1

sum_mc_plot_joint <- 
  plot(summary_default, plot = FALSE, join = first_mc_ols$nice_names[4:6])

sum_mc_plot_joint$b1
```


### Create a LaTeX table of your results with `tidy_mc_latex()`

Using `tidy_mc_latex` the user can present the results from `future_mc` directly into a LaTeX document using all the benefits from the `kableExtra` package. The first and main argument `x` needed by `tidy_mc_latex` is a `summary.mc` object obtained from `summary.mc()`. To present the results in a comprehensive manner the function requires that all summarized outputs in `summary.mc` be scalar numeric results for all parameter combinations. In case, the summarizing function returns more than one argument then this will be presented in the table as an `NA` value. The second argument of the function is `repetitions_set` which allows the user to see extract the certain values of the "path" of the summarized results of `fun`. To illustrate this we use the MC results for the OLS example:


```{r}
tidy_mc_latex(
  x = summary(first_mc_ols),
  repetitions_set = c(10, 1000)
) %>% 
  print()
```

The resulting table is composed of two panels, which corresponds to the length of `repetitions_set`. In them the columns correspond to the results of the summarizing functions for `b0`, `b1`, `b2`, and `sigma2`, and the rows correspond to specific combinations of the parameters provided in `parameter_list`. The footnote in the table shows the number of repetitions and the total parameter combinations provided to `future_mc`.

Moreover, the next three arguments in `tidy_mc_latex` are comfort options to select which results of `summary.mc` depending on the parameter combinations will be presented in the table. On one hand, The argument `which_setup` allows the user to make use of the `nice_names` of the parameter combinations in the returned object by `future_mc()` to subset the rows in the table. On the other hand, the argument `parameter_comb` is used to directly filter the parameters by their values. This argument requires a named list, containing vector or scalar values of all parameters to be filtered from. The user must only provide one of this arguments at a time. We show how to make use of both parameters to subset the rows of table for $n = 100$ and $inc_{x2}=1$:

```{r}
tidy_mc_latex(
  x = summary(first_mc_ols),
  repetitions_set = c(10, 1000),
  which_setup = first_mc_ols$nice_names[1]) %>% 
  print()

tidy_mc_latex(
  x = summary(first_mc_ols),
  repetitions_set = c(10, 1000),
  parameter_comb = list(n = 100, inc_x2 = 1)) %>% 
  print()
```

The user can also subset the outputs of the original function (columns in the table) using the parameter `which_out`. This is done using a character vector with the names of the outputs, e.g. to only show the columns for `b0` and `sigma2` the user needs to set `which_out = c("b0", "sigma2")`.

Lastly, by providing a named list to the argument `kable_options`, the user can change all arguments of the underlying function `kable::kbl()`. The names of the list have to be equal to the names of the arguments of the function and the contents of every element also has to fullfill its requirements. We provide an example of how this list should be constructed, but for optimal usage we strongly recommend the user to see the documentation of the `kable::kbl()` function.

To allow for further customization the returned object by `tidy_mc_latex` is of class `knitr_kable`, therefore the user can utilize most functions from the \texttt{kableExtra} package in the standard tidyverse manner. For example:

```{r}
tidy_mc_latex(summary(first_mc_ols), 
              repetitions_set = c(10, 1000),
              kable_options = list(
                col.names = c("Number of observations",
                              "$x_2$ included or not",
                              "$\\beta_0$", "$\\beta_1$",
                              "$\\beta_2$", "$s^2$"), 
                caption = "Ommited variable bias MC results",
                escape = FALSE
              )
) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position") %>% 
  print()
```

























# Comparison to other Monte Carlo Approaches in R

As already stated our conceptualization of an MCS implementation is based upon the basic requirements of this technique and framing the functions into the \texttt{tidyverse} structure. Previously, the \texttt{MonteCarlo} package already developed a convenient framework for the study and paralellised implementation of MCS, to which we compare the structure of our package. The main function for running a MCS in the `MonteCarlo` is the function of the eponymous name. 

Both our `future_mc` and the `MonteCarlo` functions have two main divisions on their structure. First, we have the set-up of the arguments, data containers and error checking, parts of the function. Which can be called as the preamble of the simulation. Lastly, the actual simulation of the MC study over a parameter grid specified by the user. The main differences between our implementation and the `MonteCarlo` packages lay in these two steps of the functions.

On one hand, as mentioned the whole development of our package draws from the benefits of the tidyverse functions. For example: the creation of parameter grids, the structure of the data and repeated calculations, rely heavily in functions provided by the `stringr`, `tibble` and `purrr` packages. Most importantly, for all repeated calculations that normally are handled by for loops we implement them with their `purrr` counterparts. These are all implemented keeping in mind the type of the object to be handled in order to reduce computation time, i.e. the mapping functions are tailored for dealing with specific data types. In contrast, the `MonteCarlo` function is built within a base `R` framework. Moreover, to offer flexibility to the user, the function uses a high number of strings for the creation of for loops, containers and parameter grids which are then parsed and evaluated inside the function.

On the other hand, when it comes to the implementation of the paralellised simulation both functions difer totally from each other. The `MonteCarlo` function is built around the implementation of the `snow` package. This package deals.    




# Conclusion
With the tidyMC package we provide research an easy and comfortable way to to Monte Carlo Studies. 


# Strucutre
-Introduction to MCS (5)
- How it works in our package (10)
  - parallelisation plan
  - function
  - return objects
    - objects
    - summary
    - plots
    - tables 
  - exampl of outputs
  - extension: bootstrap
- Comparison to Monte Carlos package (3)
  - objects
  - speed
    -bench::mark
- Vignette

\end{document}

