---
title: "tidyMC"
subtitle: "An easy-to-use package for Monte-Carlo Simulations"
type: "Report"
author: "Ignacio Moreira Lara, Stefan Linner, Konstantin Lehmann"
discipline: "M.Sc. Econometrics"
date: "`r Sys.Date()`"
supervisor: "Jens Klenke"
secondsupervisor: "Martin C. Arnold"
studid: 230658, 233565, 229994
cols_authors: 4
estdegree_emester: "Summer Term 2022"
deadline: "06.09.2022"
output:
  pdf_document:
    extra_dependencies: ["lmodern", "mathtools", "amsmath", "amsfonts", "soul"]
    keep_tex: yes
    template: template.tex
    fig_caption: yes
    citation_package: biblatex
    number_sections: false
toc: false
lot: false
lof: false
graphics: true
biblio-title: References
fontsize: 10pt
geometry: lmargin=2.5cm,rmargin=2.5cm,tmargin=2.5cm,bmargin=2.5cm
biblio-files: references_tidy.bib
classoption: a4paper
language: english
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# library(profvis)
# library(purrr)
# library(dplyr)
# library(tibble)
# library(rlang)
# library(ggplot2)
library(tidyMC)
library(magrittr)
# devtools::load_all()
```

# Introduction
Monte Carlo Simulations (henceforth MCS) are used to study the properties of econometrics inference techniques by simulation. 
They are almost always part of theoretical econometric research to study the performance of some inference technique. They supplement theoretical research most often in one of four ways. Firstly, they are used to assess the performance of asymptotically valid techniques in smaller samples. Secondly, they are  used to assess how robust a technique is to violations of its theoretical assumptions. Thirdly, they allow to compare the performance of different techniques for a given data generating process (DGP). Fourthly, MCS allows to investigate the properties of inference techniques for which no analytic solution exists.  Moreover, MCS itself can be used as a statistical inference technique. For example, Bootstrap Inference can be conceptualized as a special case of MCS. Beyond these examples, there are many more areas where MCS is used. However, independent of its use-case, easy and efficient implementation of MCS is currently only sparsely available.

<!-- Na: Monte Carlo Simulations (henceforth MCS) are used to study the properties statistical techniques and theories by simulation.
They are almost always part of theoretical statistical research to research the empirical behavior of some theory. MCS have been proven to be usefull in almost all fields of statistics, among some examples we have: the assessment of the performance of asymptotically valid techniques in smaller samples,the analysis of the robustness of statistical techniques to violations of theoretical assumptions, or to compare the performance of different methodologies when applied to a given data generating process (DGP). Moreover, MCS are also regarded as a technique of statistical inference by themselves. For example, Bootstrap Inference can be conceptualized as a special case of using MCS. Independent of its use-case, easy and streamed-lined implementations of MCS are currently sparsely available.-->

<!-- Na: With our \texttt{tidyMC} package, we want to offer academic and private users an easy and efficient manner to include MCS in their application through the use of the programming language R. For one, using \texttt{`tidyMC`} we enable the user a way to easily speed up MCS by providing efficient parallelization options over a pre-specified parameter grid. Because MCS involves repeated computation, using parallel workers allows for significant computation time reductions. For another, \texttt{`tidyMC`} returns an easy-to-work-with output, which allows the user to access the result of all simulations for every combination of the parameter grid. Moreover, \texttt{`tidyMC`} provides functions to effectively communicate the results of the MCS in a highly customizable setting.  Using the output, the simulation results can then be easily visualized using the package's plot function. Since the function returns a ggplot object, users can customize the object to their liking. Additionally, the package provides a function that converts the results into print-ready LaTeX tables, which are heavily customizable and thereby allow the users to effectively present their results. -->


<!-- Na: This report is structured as follows. Section \@ref(monte-carlo-simulation) gives an introduction as to why and how MCS work, and an example of the properties of OLS is presented. Section \@ref(package-principles) explains the coding practices followed during the development and gives a conceptual overview of how MCS are implemented in R. Section \@ref(vignette) presents tidyMC's vignette and gives a detailed description on the functionalities of the package, while providing an an easy-to-follow guide on how to implement MCS. Section \@ref(comparison-to-other-monte-carlo-approaches-in-r) benchmarks the performance of tidyMC in comparison to the MonteCarlo package and other potential MCS implementations.  Section \@ref(conclusion) concludes.-->

With our \texttt{tidyMC} package, we want to enable researchers to easily and efficiently include MCS in their research using the programming language R. For one, \texttt{`tidyMC`} allows to easily speed up MCS by providing efficient parallelization options over a pre-specified parameter grid. Because MCS involves repeated computation, using parallel workers allows for significant computation time reductions. For another, \texttt{`tidyMC`} returns an easy to work with output. The output allows to access the result of all simulations for every parameter combination in the parameter grid. Moreover, \texttt{`tidyMC`} provides functions to effectively communicate the results of the MCS.  Using the output, the simulation results can then be easily visualized using the package's plot function. Because the function returns a ggplot object, researchers can customize the object to their liking. Additionally, the package provides a function that converts the results into publication-ready LaTex tables. The table is heavily customizable and thereby allows researchers to effectively communicate their results. 

This report is structured as follows. Section \@ref(monte-carlo-simulation) gives an introduction to why and how Monte Carlo 
simulations work and provides a simple OLS example. Section \@ref(package-principles) explains the coding practices we followed and gives a conceptual overview of how we implemented MCS in R. Section \@ref(vignette) presents tidyMC's vignette. The vignette gives an easy-to-follow guide on how to implement MCS using the tidyMC package. Section \@ref(comparison-to-other-monte-carlo-approaches-in-r) compares the performance of tidyMC to the performance of the MonteCarlo package and other potential MCS implementations.  Section \@ref(conclusion) concludes. 

With our \texttt{tidyMC} package, we want to enable researchers to easily and efficiently include MCS in their research using the programming language R. For one, \texttt{`tidyMC`} allows to easily speed up MCS by providing efficient parallelization options over a pre-specified parameter grid. Because MCS involves repeated computation, using parallel workers allows for significant computation time reductions. For another, \texttt{`tidyMC`} returns an easy to work with output. The output allows to access the result of all simulations for every parameter combination in the parameter grid. Moreover, \texttt{`tidyMC`} provides functions to effectively communicate the results of the MCS.  Using the output, the simulation results can then be easily visualized using the package's plot function. Because the function returns a ggplot object, researchers can customize the object to their liking. Additionally, the package provides a function that converts the results into publication-ready LaTex tables. The table is heavily customizable and thereby allows researchers to effectively communicate their results. 

This report is structured as follows. Section \@ref(monte-carlo-simulation) gives an introduction to why and how Monte Carlo 
simulations work and provides a simple OLS example. Section \@ref(package-principles) explains the coding practices we followed and gives a conceptual overview of how we implemented MCS in R. Section \@ref(vignette) presents tidyMC's vignette. The vignette gives an easy-to-follow guide on how to implement MCS using the tidyMC package. Section \@ref(comparison-to-other-monte-carlo-approaches-in-r) compares the performance of tidyMC to the performance of the MonteCarlo package and other potential MCS implementations.  Section \@ref(conclusion) concludes. 

# Monte Carlo Simulation {MCS}
MCS allows analyzing the properties of classic econometric inference techniques. As a simulation-based technique, MCS applies a statistical procedure to many synthetically created samples. The repeated application of the procedure to a fully known DGP helps to investigate the properties of statistical techniques in a wide set of settings. It is possible to use MCS as a simulation-based inference technique itself. In this section, we want to give a brief overview of how and in which circumstances work, mainly following <!-- \citep{kiviet_monte_2011}. -->



## Pseudo Random Number Generation and the Data Generating Process
Using MCS on computers has the great advantage that, with the necessary information, the simulation results can be replicated on most machines. This is possible because, given seed and algorithm, the numbers created by a random number generator are completely reproducible. 
MCS generally starts with a synthetically created i.i.d. sample. Computers are, however, not able to generate truly random draws from different distributions. Instead, the computer draws from different distributions that are generated through pseudo-random draws from a uniform distribution.  Draws from a uniform distribution are created by using so-called random number generators (RNG). These algorithms are applied to a natural number, called the seed. The resulting values are pseudo-random because they are indistinguishable from truly random numbers but are fully determined by the combination of the algorithm and the seed. The combined knowledge of the algorithm and the seed allows exact replication of a series of pseudo-random numbers generated. The purpose of the \texttt{`tidyMC`} -package is to additionally allow easy parallelization of the MCS. With parallel computing, special attention has to be paid to creating disjoint and sufficiently long sets of draws from a uniform distribution. Our package builds on the Lâ€™Ecuyer-CMRG RNG streams implemented in \texttt{`furrr`}. The algorithm creates reproducible sets of numbers for each parallel worker, using an integer seed of length 7. Alternatively, a seed of length 1 is accepted, which corresponds to a valid seed of length 7. Because the algorithm creates a subset of random numbers for each worker, the stream and hence the MCS results are only reproducible if the same number of parallel workers is used. Moreover, our function allows supplying user-generated lists of random variables. 
Complex multivariate distributions can then be simulated as functions of different standard distributions. This allows us to generate and work with distributions that are analytically not manageable.

<!--The possibility to replicate the draws allows for exactly reproducing results that build on the pseudo-randomly generated number on different computers.   The most common algorithm, as well as R's standard algorithm, used for the generation of pseudo-random draws from a standard uniform distribution, is the Mersenne-Twister algorithm. There are however more algorithms available. In R it is also possible to specify your own algorithm to create pseudo-random numbers.

Generating pseudo-random numbers from more complex distributions uses the distribution's cumulative distribution function (CDF). It can be shown that every random variable $X$ has a CDF $F$ if $X = F^{-1}(U)$, where U is a random variable uniformly distributed on $(0,1)$. Pseudo-random draws from different probability distributions are conceptually implemented by applying the inverse of CDF to pseudo-random numbers from the uniform distribution. Direct application of the inverse CDF is however often computationally time-consuming and requires that the inverse CDF is analytically available. To account for the two shortcomings different approaches have been developed for specific distributions, that also easily extend to random vectors. While they build on the idea to use the inverse of the CDF, their concrete design is out of the scope of this paper. A general overview can be found in the documentation of the respective R-functions. --> 



## Monte Carlo Distribution Approximation
MCS is most commonly used to infer properties of the distribution of statistics in a fixed setting, i.e. for a prespecified DGP. The simulation results hence hold only for the prespecified DGP. Because it additionally only approximates the distribution numerically, we need to control for the resulting approximation inaccuracies.  In MCS we generally simulate the distribution of a statistic $q_n$. The statistic can often be expressed as a function of a parameter vector $\beta$, some deterministic variables $D$, some random variables $v$, and a given number of observations, s.t. $q_n = q_n(\beta,D,v,n)$. What a Monte Carlos simulation ultimately achieves is a numerical approximation of the true distribution of $q_n$ for the specified DGP. Let $q_n^R$ be the statistic generated by the $R^th$ Monte Carlo Simulation. Then the histogram of all $q_n^R$ is an unbiased and consistent estimator of $q_n$. We are hence able to control the precision of the approximation by setting the number of Monte Carlo estimates. Using the resulting distribution $q_n^R$ we can then use different statistics such as mean and variance to summarize the distribution of the statistic for the prespecified DGP. The approach can of course be easily extended to a vector of statistics $q_n$. 


## Monte Carlo Best Practices
@cite{dude} gives a few things that need to be considered when doing and presenting an MCS. The results should of course allow the audience to get a precise picture of the Monte Carlo experiment. MCS generally involves testing the attributes of $q_n$ not only for one DGP but for a wide set of DGPs that may include nuisance parameters that may significantly alter the distribution.
Instead of going through every use case, we next describe one specific MCS use case. The insights from that use case should however be easily transferable to other MCS applications. One way to perform MCS is mimic analytic derivations. For example, if properties of an asymptotically consistent technique are studied, the MCS should include different nuisance parameters over increasing sample sizes. The report of the results should then include the technique's key performance indicators, such as bias and efficiency, over different combinations of nuisance parameters and sample sizes. As the parameters are the explanatory variables of the MCS @cite{dude}, their values have to be chosen with care to appropriately represent the results from the experiment.  The reported representative selection of sample size and nuisance parameters should then show the - potentially nonlinear- behavior of the key indicators of the performance of the technique. As the later sections will show, \texttt{`tidyMC`} provides easy options to define an arbitrarily large parameter grid to use for the MCS as well as user-defined performance indicators  The packages summary functions allow the researcher to get a quick overview of the results of the combinations defined in the parameter grid. The plot and table functions allow afterward to easily communicate the desired results. Due to the flexible design of the \texttt{`tidyMC`}, the parameter grid can easily be extended to include different estimators for comparisons. It also allows using the distribution of the data itself to generate a new sample, from which we can then infer the properties of an estimator. To make things more concrete we next provide an easy-to-follow example.



<!-- ### Presenting MCS findngs
p. 122 add maybe here? For example we might be interested in the ability of OLS to estimate the variable parameter $\beta_1$ of a simple linear regression model with deterministic regressor. -->
<!-- In that case specify the model $y_i = \beta_0 + \beta_1 x_i + \epsilon_i$ with corresponding true population paramterers $\theta  = (\beta_0, \beta_1)$, $D = X$ a $n \times 2$ matrix of the deterministic x and the intercept $\beta_0$, and $c = \epsilon$ a $n \times 1$ of $\mathcal{N}(0, \sigma_\epsilon)$ as a normally distributed error term. Using OLS, we estimate $\hat{\beta_1}$ as the second element of $(X^TX)^{-1}X^Ty$. With OLS then $\hat{\beta}_1(\theta, D, v)$. In a MCS we would then generate r $\hat{\beta_1}$ to study how well OLS is able to capture the true $\beta_1$.  -->
<!-- Show distribution of interval  -->

## OLS consistency
<!-- Add Hayashi as generl source in this chapter? -->
To demonstrate how a MCS works, we provide an example using the estimation of a linear model using the ordinary least squares(OLS) estimator. Given a dependent variable $y$ and a set of i.id. regressors $X = \{x_1, x_2\}$ we consider the linear DGP 
\begin{equation}
	\label{eq_DGP}
	y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \varepsilon,
\end{equation}  
where $\beta  = \{\beta_0, \beta_1, \beta_2\}$ are the coefficients and $\varepsilon$ is a normally distributed error term with variance $\sigma^2$, i.e. $\varepsilon \sim \mathcal{N}(0,\sigma^2)$. The corresponding OLS estimators $\hat{beta}$ and $s^2$ for $\beta$ and $\sigma^2$  are
\begin{align}
	\hat{\beta} = (XX)^{-1} XY,\\
	s^2 =   \frac{1}{n-k} \hat{\varepsilon}' \hat{\varepsilon},
\end{align}
where $k = 3$ is the number of regressors and $\hat{\varepsilon}$ is the vector of residuals. Both estimators are consistent and unbiased. Accordingly OLS should be able to correctly estimate the coefficients for every sample size, while the precision of the estimates should increase in the sample size. 

<!-- Maybe add also estimator of the variance here. We know the theoretical variance of the coefficients and we can then add that to the plot: nice demonstration of how to amend the outputted ggplot object. Na: I think is too much for how the table will look in the example table -->

\noindent Using a MCS we can demonstrate the properties of the OLS estimator. Fixing the coefficients $\beta = \{1, 4, 5\}$ and $\sigma^2 = 3$, we generate different DGPs using different normal distributions to generate the dependent variables  $x_1$ and $x_2$. Additionally, we generate $\varepsilon$ from its respective distribution, and we estimate OLS on this sample. The number of observations we use is set to $n = \{100, 200, 300\}$, which will be used to assess the convergence of the OLS estimators.  We repeat the estimation 10000 times for each $n$.

We present the results in table \ref{tab:ols_table}, where the first column is related to the number of observations we use in the estimation. The last 4 columns show the results' mean over for each parameter combination up to an specific repetition number. In the first panel the mean over the estimated coefficients from the ten first repetitions is calculated; the subsequent panel shows the mean calculated using all Monte Carlo repetitions. 
<!-- What dies that mean, Na: is the way our latex tables work, we calculate the results using a handful of MC results and the table extracts the path. Everything we do here has to be done by our functions-->
The results demonstrate the performance of OLS estimation with increasing sample sizes. As expected figure \l{(XX)} and table \hl{(XX)}  confirm that a bigger sample size leads to a more precise estimation of the underlying population values. Comparing both panels, we see that this behavior is just confirmed, as the estimated values do not differ and they become more precise.
<!-- Table should include se of the coefficients. Na: If we include them they are gonna be next to the coefficients not in a nice OLS output way, because of the way our function gives the table output-->

```{r, echo = FALSE, eval = TRUE, results = "hide", message=FALSE, fig.show='hide'}
ols_test <-
  function(b0, b1, b2, n, sigma2, param_x1, param_x2, inc_x2){

    # generation of data
    x1 <- rnorm(n = n, mean = param_x1[1], sd = param_x1[2])
    x2 <- rnorm(n = n,  mean = param_x2[1], sd = param_x2[2])
    e <- rnorm(n, sd = sqrt(sigma2))
    y <- b0 + b1*x1 + b2*x2 + e

    if (inc_x2 == 0){
      x2 <- x2 * inc_x2
    }

    # application of method
    estim <- lm(y ~ x1 + x2)

    # evaluation of the result for a single repetition and parameter combination
    out <- list(B0 = estim$coefficients[1],
                B1 = estim$coefficients[2],
                B2 = estim$coefficients[3],
                s2 = var(estim$residuals))
    return(out)
  }


param_list_ols <-
  list(n = c(100, 200, 300))

ols <- future_mc(fun = ols_test, repetitions = 10000, param_list = param_list_ols,
                 b0 = 1, b1 = 4, b2 = 5, param_x1 = c(1,2), param_x2 = c(3,4),
                 sigma2 = 3, inc_x2 = 1)
ols_plots <- plot(ols, plot = FALSE)
```

```{r ols_table, echo = FALSE}

tidy_mc_latex(summary(ols), repetitions_set = c(10, 10000),
                           column_names = c("Number of observations",
                                            "$\\beta_0$", "$\\beta_1$",
                                            "$\\beta_2$", "$s^2$"),
              caption = "OLS consistency MC results") %>%
  kableExtra::kable_styling(latex_options = "HOLD_position")

```
Similarly to show the convergence of the estimators in a graphical manner, we present histograms of the estimated coefficients for all values of $n$. We present the densities for $\hat{\beta_1}$ and $s^2$ in figures \ref{fig:ols_b1} and \hl{(XX)}, and include the remaining plots in the Appendix.
The pattern for both figures is clear, the increase in $n$ reduces the variance of the estimator around the true value, thus the convergence of the OLS estimators is empirically visible.

```{r ols_b1, echo = FALSE, fig.cap="MC $\\beta_1$ results"}
ols_plots$B1

```

```{r ols_s2, echo = FALSE, fig.cap="MC $s^2$ results"}
ols_plots$s2

```



##Ommited variable bias and irrelevant regressor inclusion

Moreover, another common problem for estimation is the inclusion of suitable regressors into the model. Both the inclusion of irrelevant variables and the absence of relevant ones into the regression model cause problems when estimating the true parameters. In this section, we will test the impact both of these problems on the estimated values.
\noindent We continue with the same structure as in equation \eqref{eq_DGP}, we will test, however, the case when $\beta_2 = 0$ which means that $x_2$ has no influence on $y$. This causes a problem in the estimation when the researcher does not know the underlying DGP and includes $x_2$ to the model, because of lack of information or convenience. \textit{A priori} the expected result is that the estimated coefficient associated with this new variable will be 0, while the variance of the residuals however will increase.

\noindent We test this hypothesis using a Monte Carlo study, where we use the same coefficient values as for the base example, except that we set $\beta_2=0$. Then we run an OLS model with $x_1$ and $x_2$ as the regressors using $n = (100, 200, 300)$. Lastly, we repeat this 10000 times for every value of $n$. We present the obtained results in table \ref{eq:irr_ols_table}. Two panels are presented again, one for the mean results of the ten first MC repetitions and the second for all repetitions. Again the hypothesis about the behavior of the coefficients is proven to be right, i.e. the estimators for $\beta_0$ and $\beta_1$ appear to converge to the true value. In contrast, the estimator for $\beta_2$ is marginally different from zero for all values of $n$, and from the overall mean results we conclude that this behavior does not change. Lastly, the last point of the hypothesis about the estimator of the variance of the error term is also proven to be right. This is because the results for the estimator $s^2$ have higher values compared to the ones obtained in table \ref{ols_table}. 

```{r, echo = FALSE, eval = TRUE, results = "hide", message=FALSE}
ols_irr <- future_mc(fun = ols_test, repetitions = 10000,
                     param_list = param_list_ols, b0 = 1, b1 = 4,
                     b2 = 0, param_x1 = c(1,2), param_x2 = c(3,4),
                     sigma2 = 3, inc_x2 = 1)

```


```{r irr_ols_table, echo = FALSE}
tidy_mc_latex(summary(ols_irr), repetitions_set = c(10, 10000),
                               column_names = c("Number of observations",
                                            "$\\beta_0$", "$\\beta_1$",
                                                "$\\beta_2$", "$s^2$"),
              caption = "MC OLS results with an irrelevant variable") %>%
  kableExtra::kable_styling(latex_options = "HOLD_position")

```

Lastly, we test the effects of estimating a model using only $x_1$ when the underlying DGP follows the structure of \eqref{eq_DGP}, this problem is most commonly known as having an omitted variable bias. The theoretical consequences of this problem are related to the consistency and unbiasedness of the estimators. Since it is necessary that $x_1$ and $x_2$ share a degree of correlation between them, the absence of one of them in the regression model will cause the available variable to be correlated with the error term, thus violating one of the main assumptions of this methodology. This correlation will lead to an estimator of $\beta_1$ to have a higher or lower expected value (depending on the sign of the correlation) in comparison to the true parameter.

# Package Principles {MCS}


# Vignette{vignette}


```{r , echo = FALSE , eval = TRUE, results = "hide", message=FALSE}
param_list_ols <- param_list_ols <-
  list(n = c(100, 200, 300), inc_x2 = c(0,1))

ols_omi <- future_mc(fun = ols_test, repetitions = 10000,
                     param_list = param_list_ols, b0 = 1, b1 = 4,
                     b2 = 5, param_x1 = c(1,2), param_x2 = c(3,4),
                     sigma2 = 3)


```
Operationally, we test this theoretical behavior using the same structure as for the last examples, now however we do not include $x_2$ into our estimated model. We present the results in table \ref{tab:ommiols}. To see a clearer difference we present the results for both models where $x_2$ is included and where is not. We see a clear difference in the estimated coefficients, on one hand the estimated intercept is completely overestimated, averaging around a value of 16 no matter the number of observations used or the number of MC replications. On the other hand, the estimated variance of the error term is also completely overestimated and does not seem to converge to the real value. We conclude that the absence of one important variable in the model has a bigger impact when compared to the inclusion of an irrelevant variable.

```{r ommiols, echo = FALSE}
tidy_mc_latex(summary(ols_omi), repetitions_set = c(10, 10000),
                           column_names = c("Number of observations",
                                            "$x_2$ included or not",
                                            "$\\beta_0$", "$\\beta_1$",
                                            "$\\beta_2$", "$s^2$"),
              caption = "Ommited variable bias MC results") %>%
  kableExtra::kable_styling(latex_options = "HOLD_position")

```






# Package overview

Monte Carlo Simulations aim to uncover properties of statistical inference techniques. 
At its core, a Monte Carlo Simulations works through application of the techniques to repeatedly drawn samples from a pre-specified data generating process.  The `tidyMC` package aims to cover and simplify the whole workflow of running a Monte Carlo simulation in either an academic or professional setting. Thus, `tidyMC` aims to provide functions for the following steps:

Running a Monte Carlo Simulation for a user defined function and given parameters using `future_mc()`
Summarizing the results by (optionally) user defined summary functions using `summary.mc()`
Creating plots of the Monte Carlo Simulation and its results, which can be modified by the user using `plot.mc()` and `plot.summary.mc()`
Creating a LaTeX table summarizing the results of the Monte Carlo Simulation using `tidy_mc_latex()`

In the following subsections we will show you how you can implement those steps using the `tidyMC` package.


## Installing tidyMC

Until now, the `tidyMC` package is not on CRAN, thus you need to download the development version from [GitHub](https://github.com/stefanlinner/tidyMC) as follows:

```{r, eval=FALSE}
# install.packages("devtools")
devtools::install_github("stefanlinner/tidyMC")
```

Afterwards you can load the package:

```{r}
library(tidyMC)
library(magrittr)
```


### Run your first Monte Carlo Simulation with `future_mc()`

`future_mc()` allows you to run a Monte Carlo Simulation for a user defined function and given parameters. The first argument of `future_mc()` is `fun` which has to be a function that handles the generation of data, the application of the method of interest and the evaluation of the result for a single repetition and parameter combination. `future_mc()` handles the generation of loops over the desired parameter grids and the repetition of the Monte Carlo experiment for each of the parameter constellations. Consider the following example for `fun` and note that it performs the required tasks of generating data, applying the method and evaluating the results: 

```{r}
# fun
ols_test <- 
  function(b0, b1, b2, n, sigma2, param_x1, param_x2, inc_x2){
    
    # generation of data
    x1 <- rnorm(n = n, mean = param_x1[1], sd = param_x1[2])
    x2 <- rnorm(n = n,  mean = param_x2[1], sd = param_x2[2])
    e <- rnorm(n, sd = sqrt(sigma2))
    y <- b0 + b1*x1 + b2*x2 + e
    
    if (inc_x2 == 0){
      x2 <- x2 * inc_x2
    }
    
    # application of method
    estim <- lm(y ~ x1 + x2)
    
    # evaluation of the result for a single repetition and parameter combination
    out <- list(b0 = estim$coefficients[1],
                b1 = estim$coefficients[2],
                b2 = estim$coefficients[3],
                sigma2 = var(estim$residuals))
    return(out)
  }
```

The second argument of `future_mc()` is `repetitions` which should be an integer specifying the number of Monte Carlo iterations. While the third argument `param_list` should be a list whose components are named after the parameters of `fun` which should vary for the different Monte Carlo Simulation and each component is a vector containing the desired grid values for the parameter. Consider the following example for `param_list` and note that its components are named accordingly to the parameters of `ols_test`: `n` and `inc_x2`, respectively:

```{r}
# param_list
param_list_ols <- 
  list(n = c(100, 200, 300), inc_x2 = c(0,1))
```

`future_mc()` takes care of creating all possible parameter combinations of `param_list` and runs the Monte Carlo Simulation over all of these \hl{for all possible combinations}. The `...` argument can be used to specify further arguments of `fun` which are not contained in `param_list`. Those arguments will be held fixed for all parameter combinations. In our OLS example the arguments are `b0`, `b1`, `b2`, `sigma2`, `param_x1`, and `param_x2`.

Moreover, there are four formal requirements that `fun` and thus `ols_test` have to fulfill:

The arguments of `fun` which are present in `param_list` have to be scalar values. Note that the arguments of `ols_test` which are contained in `param_list_ols`: `n` and `inc_x2` are scalar values. The remaining arguments of `ols_test` are allowed to take non-scalar values.
Every variable used inside `fun` has either to be defined inside `fun` or given as an argument through the `...` argument.
The value returned by `fun` has to be a named list. In our example the names of the returned list are `b0`, `b1`, `b2`, and `sigma2`.
The names of the returned values and those of the arguments contained in `param_list` need to be different. Moreover, they cannot be `params`, `repetitions` or `setup` as these names are already occupied. Note that `b0`, `b1`, `b2`, and `sigma2` are the names of the returned values as well as names of arguments of `ols_test`. However, none of those arguments is contained in `param_list_ols`. If we would add either of those variables to `param_list_ols` we would need to change the name of the returned value for the respective variable.

We recommend to even further restrict the return value of `fun` to be a named list of scalars. This allows you to use all comfort functions of the `tidyMC` package. As you can see, we did that for `ols_test`.


The argument `parallelisation_plan` allows the user to set a parallelisation plan. While the argument `parallelisation_options` allows the user to fine tune functions, such as `furrr::future_map()` by `furrr::furrr_options()`. Moreover, the user can also decide not to run the Monte Carlo in parallel by setting `parallel = FALSE`. As default `future_mc()` runs a quick check by running a single test-iteration for each parameter combination in order to check for possible errors in `fun`. If a error occurs the user not only receives the error message but also the parameter combinations for which the error occurred:

<!-- maybe also say that tests can be skipped? Additionally maybe also give an example of a parralelisation playn, quickly laying out the main options? -->

```{r, error=TRUE}
set.seed(101)
first_mc_ols <- future_mc(
  fun = ols_test, 
  repetitions = 1000, 
  param_list = param_list_ols, 
  b0 = 1, 
  b1 = 4, 
  b2 = 5, 
  sigma2 = -2,
  param_x1 = c(0,5),
  param_x2 = c(0,6),
  check = TRUE
)
```

The attentive reader might already have noticed that we specified `sigma2 = -2` which doesn't make sense, as the variance of the error term cannot be negative. 
<!-- The attentive reader might have already noticed that we misspecifed the variance ?`sigma2 = -2`. By defintion, the variance is non-negtaive and the sepcified function is hence nonsenscial. As expected, the failed check informs about the source of the mistake, which impacts all parameter combinations specified.-->
This results in a failed check for all parameter combinations, as this parameter is held fixed for any combination. Once we correct that mistake, we can run our first Monte Carlo Simulation:

```{r}
set.seed(101)
first_mc_ols <- future_mc(
  fun = ols_test, 
  repetitions = 1000, 
  param_list = param_list_ols, 
  b0 = 1, 
  b1 = 4, 
  b2 = 5, 
  sigma2 = 2, # correctly specify sigma2
  param_x1 = c(0,5),
  param_x2 = c(0,6),
  check = TRUE
)
```

`future_mc` returns a list of type `mc` and length `r length(first_mc_ols)` consisting of a tibble (`first_mc_ols$output`) containing the return value of `fun` for each iteration and parameter combination. In our case `first_mc_ols$output` contains a column for each output `b0`, `b1`, `b2`, and `sigma2`, as well as a column for each parameter in `param_list_ols` and a column containing the `nice_names` of the parameter combinations. Overall the `first_mc_ols$output` consists of `r nrow(first_mc_ols$output)` rows, i.e., for each parameter combination 1.000 rows: 

```{r}
first_mc_ols$output
```

If `ols_test` would not return a named list of scalars, but a named list of non-scalars, then `first_mc_ols$output` would not contain a column for each output, but a single column containing the named list of non-scalars for each iteration and parameter combination.

Moreover, `first_mc_ols` returns much other information about the Monte Carlo Simulation that can be printed in a dense representation:

```{r}
first_mc_ols
```


### Summarize your results with `summary.mc()`

If `fun` returns a named list of scalars the user can use `summary.mc()` to summarize all Monte Carlo results. The first argument of the function is an object of class `mc` returned by `future_mc()`. The next argument `sum_funs` determines which summarizing functions will be used on the simulation results. The functions can be provided for any combination of: parameter combinations resulting from `param_list`, and the outputs of `fun`. Every specified function can only take one argument, which is the vector (with length `repetitions`) for every output. We will present all customization options of `sum_funs` in a stepwise manner. 

The first option of summarizing the results is given by just providing the `mc` object to `summary.mc`. In this case, `mean()` will be applied to all numeric values and `summary()` to all non-numeric data types. When the summarizing functions return one numeric value (like `mean()`) the results are twofold:

First, a single scalar result of the function evaluated using the complete output vector is returned in the first element.

Second, a vector with length `repetitions` of numeric results from the step wise calculation of the function's result across the output's vector. We call this resulting vector as the "path" of the summarizing function. 


For the OLS example since all outputs of `ols_test` are numeric, the returned object will be a named nested list composed of four elements named after the `nice_names` returned by `future_mc()`. Each of this elements are itself lists containing the summarized outputs, i.e. `b0`, `b1`, `b2`, and `sigma2`. Lastly each of these are composed by the "path" and scalar result of `mean()`. 

<!-- If `fun` was further restricted to return a named list of scalars the function `summary.mc()` can be used to summarize the Monte Carlo results of an object of class `mc` that is returned by `future_mc()`. Using the argument `sum_funs` the user can define (different) functions which summarize the simulation results for each output (return values of `fun`) and each parameter combination. Thus, the functions inside `sum_funs` only take one argument, which is the output vector (with length `repetitions`) of one output of one specific parameter combination. The default summary functions are `mean()` for numeric outputs and `summary()` for outputs with non-numeric data types. As `ols_test` outputs are all numeric `mean()` will be used to summarize all outputs by default: -->

```{r}
# Default
summary_default <- summary(first_mc_ols)
summary_default
str(summary_default[[1]])
```

<!-- The user can define summary functions by supplying a named (nested) list to `sum_funs`. When the functions provided for each output return only one numeric value (like `mean()` but unlike `summary()`) the results are twofold: first, a single scalar result of the function evaluating the whole output vector. Second, a "path" with length `repetitions` of the step wise calculation of the function's result across the output vector. Thus, for `ols_test` -->

This nested list structure should give an idea of the reach and flexibility the `sum_funs` argument is allowed to have, since the user can specify a function for each element in this list.

For an intermediate level of customization, the user can provide a combination of summarizing functions for every output, which will be used for all parameter combination. In the case of the OLS example, if we want to apply `mean()` on all estimated coefficients, but we want to use `var()` on the MC results of `sigma2`, the `sum_funs` should have the following structure:
```{r, eval = FALSE}
# summarizing output the same way for each parameter combination with one function combination
sum_funs_ols <- list(b0 = mean, b1 = mean , b2 = mean, sigma2 = var)
```
Moreover, the user can specify any function provided it takes the output vector as only available argument.

Lastly for the last level of customization, a nested list named after the `nice_names` where every element follows the structure of the last example (components named after the outputs and each component is a function) can be specified. We present an example for this:

<!-- If the user wants to summarize the simulation results of a respective output in the same way for each parameter combination, a list whose components are named after the outputs (names of the returned list of `fun`) is supplied and each component is a function which only takes the vector of results of one output as the main argument. -->

<!-- If the user wants to summarize the simulation results of a respective output differently for different parameter combinations, a nested list has to be supplied. The components of the outter list must be equal in length and naming to the `nice_names` (see `first_mcs$nice_names`) and each component is another list (inner list). The components of the inner list are then defined the same way as above (components named after the outputs and each component is a function). -->

<!-- Here an example for the different specifications of `sum_funs`: -->

```{r}
quantile_sum <- function(x) quantile(x, probs = 0.75)

# summarizing output differently for different parameter combinations
sum_funs2 <-
  list(
    list(b0 = quantile_sum, b1 = min, b2 = min, sigma2 = mean),
    list(b0 = mean, b1 = quantile_sum, b2 = mean, sigma2 = mean),
    list(b0 = median, b1 = median, b2 = median, sigma2 = mean),
    list(b0 = max, b1 = max, b2 = max, sigma2 = mean),
    list(b0 = min, b1 = min, b2 = min, sigma2 = quantile_sum),
    list(b0 = mean, b1 = mean, b2 = quantile_sum, sigma2 = quantile_sum)
  )
names(sum_funs2) <- first_mc_ols$nice_names
summary_out_param_spec <- summary(first_mc_ols, sum_funs = sum_funs2)
```

We would like to reiterate that the provided summary functions are not restricted regarding the complexity of their return value. However, the path of the summarized output over all simulation repetitions is only returned if the provided summary functions return a single numeric value. Thus, the following comfort functions `plot.summary.mc()` and `tidy_mc_latex()` will only work in this specific case.

<!-- The provided summary functions are not restricted regarding the complexity of their return value. However, the path of the summarized output over all simulation repetitions is only returned if the provided summary functions return a single numeric value. Thus, the following comfort functions `plot.summary.mc()` and `tidy_mc_latex()` will only work in this specific case. -->


### Plot your Monte Carlo Simulation with `plot.mc()` and `plot.summary.mc()`







### Create a LaTeX table of your results with `tidy_mc_latex()`

Using `tidy_mc_latex` the user can present the results from `future_mc` directly into a LaTeX document using all the benefits from the `kableExtra` package. The first and main argument `x` needed by `tidy_mc_latex` is a `summary.mc` object obtained from `summary.mc()`. To present the results in a comprehensive manner the function requires that all summarized outputs in `summary.mc` be scalar numeric results for all parameter combinations. In case, the summarizing function returns more than one argument then this will be presented in the table as an `NA` value. The second argument of the function is `repetitions_set` which allows the user to see extract the certain values of the "path" of the summarized results of `fun`. To illustrate this we use the MC results for the OLS example:


```{r}
tidy_mc_latex(
  x = summary(first_mc_ols),
  repetitions_set = c(10, 1000),
                           column_names = c("Number of observations",
                                            "$x_2$ included or not",
                                            "$\\beta_0$", "$\\beta_1$",
                                            "$\\beta_2$", "$s^2$"))
```
The resulting table is composed of two panels, which corresponds to the length of `repetitions_set`. In them the columns correspond to the results of the summarizing functions for `b0`, `b1`, `b2`, and `sigma2`, and the rows correspond to specific combinations of the parameters provided in `parameter_list`. The footnote in the table shows the number of repetitions and the total parameter combinations provided to `future_mc`.

Moreover, the next three arguments in `tidy_mc_latex` are comfort options to select which results of `summary.mc` depending on the parameter combinations will be presented in the table. On one hand, The argument `which_setup` allows the user to make use of the `nice_names` of the parameter combinations in the returned object by `future_mc()` to subset the rows in the table. On the other hand, the argument `parameter_comb` is used to directly filter the parameters by their values. This argument requires a named list, containing vector or scalar values of all parameters to be filtered from. The user must only provide one of this arguments at a time. We show how to make use of both parameters to subset the rows of table for $n = 100$ and $inc_{x2}=1$:

```{r}
tidy_mc_latex(
  x = summary(first_mc_ols),
  repetitions_set = c(10, 1000),
  which_setup = first_mc_ols$nice_names[1],
                           column_names = c("Number of observations",
                                            "$x_2$ included or not",
                                            "$\\beta_0$", "$\\beta_1$",
                                            "$\\beta_2$", "$s^2$"))

tidy_mc_latex(
  x = summary(first_mc_ols),
  repetitions_set = c(10, 1000),
  parameter_comb = list(n = 100, inc_x2 = 1),
                           column_names = c("Number of observations",
                                            "$x_2$ included or not",
                                            "$\\beta_0$", "$\\beta_1$",
                                            "$\\beta_2$", "$s^2$"))

```
The user can also subset the outputs of the original function (columns in the table) using the parameter `which_out`. This is done using a character vector with the names of the outputs, e.g. to only show the columns for `b0` and `sigma2` the user needs to set `which_out = c("b0", "sigma2")`.

Lastly, all remaining arguments are directly related to the resulting LaTeX output, namely `caption` is used to provide the caption for the table as a string, and `column_names` which allows the user to change the final column names in the table. The latter argument must be a character vector with a length equal to the number of parameters and outputs of `fun`. For example, for the OLS example this vector would need to be of size 6. Lastly, the names are allowed to be written in standard LaTeX code, e.g. "$\beta_0$". 

To allow for further customization the returned object by `tidy_mc_latex` is of class `knitr_kable`, therefore the user can utilize most functions from the \texttt{kableExtra} package in the standard tidyverse manner. For example:

```{r}
tidy_mc_latex(summary(first_mc_ols), repetitions_set = c(10, 1000),
                           column_names = c("Number of observations",
                                            "$x_2$ included or not",
                                            "$\\beta_0$", "$\\beta_1$",
                                            "$\\beta_2$", "$s^2$"),
              caption = "Ommited variable bias MC results") %>%
  kableExtra::kable_styling(latex_options = "HOLD_position")
```
















# Comparison to other Monte Carlo Approaches in R{comparsion}


# Conclusion
With the tidyMC package we provide research an easy and confortable way to to Monte Carlo Studies. 


# Strucutre
-Introduction to MCS (5)
- How it works in our package (10)
  - parallelisation plan
  - function
  - return objects
    - objects
    - summary
    - plots
    - tables 
  - exampl of outputs
  - extension: bootstrap
- Comparison to Monte Carlos package (3)
  - objects
  - speed
    -bench::mark
- Vignette

\end{document}

